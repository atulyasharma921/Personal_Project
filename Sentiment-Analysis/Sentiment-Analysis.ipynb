{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1= pd.read_excel('C:\\\\Users\\\\Lenovo\\\\Downloads\\\\Documents\\\\ecom data reduced (2).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Great CD: My lovely Pat has one of the GREAT ...\n",
       "1        One of the best game music soundtracks - for ...\n",
       "2        Batteries died within a year ...: I bought th...\n",
       "3        works fine, but Maha Energy is better: Check ...\n",
       "4        Great for the non-audiophile: Reviewed quite ...\n",
       "                              ...                        \n",
       "7967     A wonderful mistery book: I love it. I'm a fa...\n",
       "7968     PRINT WAY, WAY TOO SMALL!!: All the stories o...\n",
       "7969     Classic is a classic: Sherlock is a classic. ...\n",
       "7970     VERY Small Type Makes Reading Difficult (Impo...\n",
       "7971     The Author Has An Odd Fascination: I read thi...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['COMMENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets bring entire document to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"COMMENTS\"]=df1[\"COMMENTS\"].apply(lambda x:\" \".join(x.lower() for x in str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       great cd: my lovely pat has one of the great v...\n",
       "1       one of the best game music soundtracks - for a...\n",
       "2       batteries died within a year ...: i bought thi...\n",
       "3       works fine, but maha energy is better: check o...\n",
       "4       great for the non-audiophile: reviewed quite a...\n",
       "                              ...                        \n",
       "7967    a wonderful mistery book: i love it. i'm a fan...\n",
       "7968    print way, way too small!!: all the stories of...\n",
       "7969    classic is a classic: sherlock is a classic. a...\n",
       "7970    very small type makes reading difficult (impos...\n",
       "7971    the author has an odd fascination: i read this...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"COMMENTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will remove all puncuations from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"COMMENTS\"]=df1[\"COMMENTS\"].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       great cd my lovely pat has one of the great vo...\n",
       "1       one of the best game music soundtracks  for a ...\n",
       "2       batteries died within a year  i bought this ch...\n",
       "3       works fine but maha energy is better check out...\n",
       "4       great for the nonaudiophile reviewed quite a b...\n",
       "                              ...                        \n",
       "7967    a wonderful mistery book i love it im a fan of...\n",
       "7968    print way way too small all the stories of she...\n",
       "7969    classic is a classic sherlock is a classic and...\n",
       "7970    very small type makes reading difficult imposs...\n",
       "7971    the author has an odd fascination i read this ...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"COMMENTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will remove all digits/numbers from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"COMMENTS\"]=df1[\"COMMENTS\"].str.replace('\\d+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       great cd my lovely pat has one of the great vo...\n",
       "1       one of the best game music soundtracks  for a ...\n",
       "2       batteries died within a year  i bought this ch...\n",
       "3       works fine but maha energy is better check out...\n",
       "4       great for the nonaudiophile reviewed quite a b...\n",
       "                              ...                        \n",
       "7967    a wonderful mistery book i love it im a fan of...\n",
       "7968    print way way too small all the stories of she...\n",
       "7969    classic is a classic sherlock is a classic and...\n",
       "7970    very small type makes reading difficult imposs...\n",
       "7971    the author has an odd fascination i read this ...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"COMMENTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improting stop words directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase you see error 'stopwords not found' run below command and re-run above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we want to add to the list of stopwords, eg your company name. use this command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop.append('Protouch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'Protouch']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we want to remove to the list of stopwords, eg your company name. use this command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop.remove('Protouch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will remove the stopwords from the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['COMMENTS']=df1['COMMENTS'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       great cd lovely pat one great voices generatio...\n",
       "1       one best game music soundtracks game didnt rea...\n",
       "2       batteries died within year bought charger jul ...\n",
       "3       works fine maha energy better check maha energ...\n",
       "4       great nonaudiophile reviewed quite bit combo p...\n",
       "                              ...                        \n",
       "7967    wonderful mistery book love im fan sherlock st...\n",
       "7968    print way way small stories sherlock holmes cr...\n",
       "7969    classic classic sherlock classic go along hyst...\n",
       "7970    small type makes reading difficult impossible ...\n",
       "7971    author odd fascination read book law school au...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['COMMENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will be stemming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       great cd love pat one great voic gener listen ...\n",
       "1       one best game music soundtrack game didnt real...\n",
       "2       batteri die within year bought charger jul wor...\n",
       "3       work fine maha energi better check maha energi...\n",
       "4       great nonaudiophil review quit bit combo playe...\n",
       "                              ...                        \n",
       "7967    wonder misteri book love im fan sherlock stori...\n",
       "7968    print way way small stori sherlock holm cram o...\n",
       "7969    classic classic sherlock classic go along hyst...\n",
       "7970    small type make read difficult imposs typefac ...\n",
       "7971    author odd fascin read book law school author ...\n",
       "Name: COMMENTS, Length: 7972, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st=PorterStemmer()\n",
    "df1['COMMENTS'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will work on Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "x = cv.fit_transform(df1['COMMENTS']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7972, 35983)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt(\"trial112.csv\", x, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaagggghhhhhhh',\n",
       " 'aaahhhh',\n",
       " 'aaarrrggghhh',\n",
       " 'aacsrunning',\n",
       " 'aages',\n",
       " 'aahhh',\n",
       " 'aaiwtlg',\n",
       " 'aalfred',\n",
       " 'aap',\n",
       " 'aardvark',\n",
       " 'aaron',\n",
       " 'aarons',\n",
       " 'aaspect',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandod',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonnes',\n",
       " 'abandons',\n",
       " 'abarca',\n",
       " 'abb',\n",
       " 'abberation',\n",
       " 'abbey',\n",
       " 'abbeys',\n",
       " 'abbott',\n",
       " 'abbreviated',\n",
       " 'abbreviation',\n",
       " 'abby',\n",
       " 'abckand',\n",
       " 'abdomial',\n",
       " 'abdominal',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abel',\n",
       " 'abendroth',\n",
       " 'abercrombie',\n",
       " 'aberdeen',\n",
       " 'abetter',\n",
       " 'abhor',\n",
       " 'abide',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ablity',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'abook',\n",
       " 'aboration',\n",
       " 'aboriginal',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abot',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'aboundthe',\n",
       " 'aboutadifferent',\n",
       " 'aboutalso',\n",
       " 'abouti',\n",
       " 'aboutmarquez',\n",
       " 'aboutthe',\n",
       " 'abovementioned',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abrasive',\n",
       " 'abreviated',\n",
       " 'abridge',\n",
       " 'abridged',\n",
       " 'abridgedaudiobook',\n",
       " 'abridgement',\n",
       " 'abridging',\n",
       " 'abroad',\n",
       " 'abroken',\n",
       " 'abrsmi',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absense',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentwould',\n",
       " 'absentyou',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'absorbancy',\n",
       " 'absorbant',\n",
       " 'absorbed',\n",
       " 'absorbency',\n",
       " 'absorbent',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'absoulutely',\n",
       " 'absoutely',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstruse',\n",
       " 'absulootly',\n",
       " 'absurd',\n",
       " 'absurdities',\n",
       " 'absurdwhy',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abusebut',\n",
       " 'abused',\n",
       " 'abuseproof',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abut',\n",
       " 'abviously',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'abyssal',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'academys',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuated',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptablethere',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessable',\n",
       " 'accessed',\n",
       " 'accessedparamount',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessoriesin',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'accolades',\n",
       " 'accomidations',\n",
       " 'accommodate',\n",
       " 'accommodates',\n",
       " 'accomodated',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishlots',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accounted',\n",
       " 'accountin',\n",
       " 'accounts',\n",
       " 'accountsource',\n",
       " 'accoustic',\n",
       " 'accross',\n",
       " 'acctually',\n",
       " 'accumulate',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accuratehe',\n",
       " 'accurately',\n",
       " 'accurrate',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accustomed',\n",
       " 'acdc',\n",
       " 'ace',\n",
       " 'acedamy',\n",
       " 'aces',\n",
       " 'acetylene',\n",
       " 'achebe',\n",
       " 'acheivement',\n",
       " 'achelis',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieving',\n",
       " 'achingand',\n",
       " 'achp',\n",
       " 'achtung',\n",
       " 'acid',\n",
       " 'acidly',\n",
       " 'acidtongued',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledgements',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'ackroyd',\n",
       " 'acne',\n",
       " 'acomplishment',\n",
       " 'acopy',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acres',\n",
       " 'acrobat',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobattalk',\n",
       " 'acronyms',\n",
       " 'across',\n",
       " 'acrosstheglobe',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acteurs',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'actingfilming',\n",
       " 'actinggood',\n",
       " 'actings',\n",
       " 'actingthe',\n",
       " 'actingvin',\n",
       " 'action',\n",
       " 'actionadventure',\n",
       " 'actionand',\n",
       " 'actionbut',\n",
       " 'actioncomedy',\n",
       " 'actioncrime',\n",
       " 'actioned',\n",
       " 'actioner',\n",
       " 'actionfantasyhistory',\n",
       " 'actionfilled',\n",
       " 'actiongraphics',\n",
       " 'actionhorror',\n",
       " 'actioni',\n",
       " 'actionpacked',\n",
       " 'actionpowerful',\n",
       " 'actions',\n",
       " 'actionswhether',\n",
       " 'actionthank',\n",
       " 'actionthe',\n",
       " 'actionthere',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activex',\n",
       " 'activialed',\n",
       " 'activist',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actnotice',\n",
       " 'actoin',\n",
       " 'actor',\n",
       " 'actoractress',\n",
       " 'actorbrendan',\n",
       " 'actorrob',\n",
       " 'actors',\n",
       " 'actorsactresses',\n",
       " 'actorsi',\n",
       " 'actorsmith',\n",
       " 'actorsthis',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actressthis',\n",
       " 'acts',\n",
       " 'actshoally',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actuallyit',\n",
       " 'actualy',\n",
       " 'actuar',\n",
       " 'actvitieshe',\n",
       " 'actwas',\n",
       " 'acually',\n",
       " 'acuerdo',\n",
       " 'acupuncturist',\n",
       " 'acurate',\n",
       " 'acused',\n",
       " 'acuses',\n",
       " 'acutally',\n",
       " 'acutely',\n",
       " 'acv',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adadptation',\n",
       " 'adage',\n",
       " 'adagio',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adamsbaum',\n",
       " 'adamsons',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adaptec',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'adaptoroverall',\n",
       " 'adaptors',\n",
       " 'add',\n",
       " 'addadhd',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'adderblack',\n",
       " 'adderfor',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addictedmy',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addional',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'additon',\n",
       " 'addmission',\n",
       " 'addon',\n",
       " 'addremove',\n",
       " 'addresed',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adduser',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adequatemore',\n",
       " 'adf',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adhesive',\n",
       " 'adidas',\n",
       " 'adition',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjustedthe',\n",
       " 'adjusters',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administartion',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'admins',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admist',\n",
       " 'admit',\n",
       " 'admitedlly',\n",
       " 'admiti',\n",
       " 'admitjohn',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admittingly',\n",
       " 'adn',\n",
       " 'ado',\n",
       " 'adobe',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescentsthe',\n",
       " 'adolph',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adorable',\n",
       " 'adorama',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adp',\n",
       " 'adquisición',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adrienne',\n",
       " 'adrift',\n",
       " 'adrogyny',\n",
       " 'adroit',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulteducation',\n",
       " 'adulteress',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'adultsi',\n",
       " 'adv',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancethe',\n",
       " 'advantage',\n",
       " 'advantagehistorical',\n",
       " 'advantages',\n",
       " 'advantagous',\n",
       " 'advent',\n",
       " 'adventerous',\n",
       " 'adventouros',\n",
       " 'adventure',\n",
       " 'adventuregonestupid',\n",
       " 'adventurer',\n",
       " 'adventurers',\n",
       " 'adventures',\n",
       " 'adventurethe',\n",
       " 'adventuring',\n",
       " 'adventurous',\n",
       " 'adverbs',\n",
       " 'adversaryas',\n",
       " 'adversity',\n",
       " 'adversly',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisedit',\n",
       " 'advertisedother',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advertisinig',\n",
       " 'advertized',\n",
       " 'adverts',\n",
       " 'advertures',\n",
       " 'advice',\n",
       " 'advices',\n",
       " 'advicestay',\n",
       " 'advisary',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advisethanksgary',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'advocates',\n",
       " 'ae',\n",
       " 'aerial',\n",
       " 'aerials',\n",
       " 'aerobed',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'aerodynamic',\n",
       " 'aerosmith',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'af',\n",
       " 'afarid',\n",
       " 'afeitadora',\n",
       " 'afeitan',\n",
       " 'afeitandome',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affectedeven',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affections',\n",
       " 'affective',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliationits',\n",
       " 'affiliations',\n",
       " 'affinity',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'affluenza',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affordablemy',\n",
       " 'affords',\n",
       " 'afformentioned',\n",
       " 'afganistan',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afi',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afield',\n",
       " 'afirmo',\n",
       " 'afis',\n",
       " 'afleck',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afr',\n",
       " 'afraid',\n",
       " 'afraidthere',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'aftenoon',\n",
       " 'afterburner',\n",
       " 'afterdo',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'aftermarket',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afteroh',\n",
       " 'afterthought',\n",
       " 'afterthoughtall',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'afterwardsbut',\n",
       " 'afterword',\n",
       " 'afterwork',\n",
       " 'afuera',\n",
       " 'ag',\n",
       " 'againa',\n",
       " 'againand',\n",
       " 'againas',\n",
       " 'againgarmin',\n",
       " 'againhappy',\n",
       " 'againi',\n",
       " 'againif',\n",
       " 'againit',\n",
       " 'againits',\n",
       " 'againmaybe',\n",
       " 'againmcdermotts',\n",
       " 'againok',\n",
       " 'againremembering',\n",
       " 'agains',\n",
       " 'againsome',\n",
       " 'againthanks',\n",
       " 'againthe',\n",
       " 'againtoo',\n",
       " 'againvery',\n",
       " 'againwere',\n",
       " 'againwhen',\n",
       " 'againwhile',\n",
       " 'againwould',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'agealso',\n",
       " 'ageas',\n",
       " 'aged',\n",
       " 'ageless',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agenope',\n",
       " 'agent',\n",
       " 'agentand',\n",
       " 'agentcom',\n",
       " 'agents',\n",
       " 'ageof',\n",
       " 'ages',\n",
       " 'agesthe',\n",
       " 'ageswhat',\n",
       " 'agewise',\n",
       " 'agey',\n",
       " 'agfaloupe',\n",
       " 'aggeivated',\n",
       " 'aggie',\n",
       " 'aggresive',\n",
       " 'aggressive',\n",
       " 'aghast',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'agitator',\n",
       " 'agnes',\n",
       " 'ago',\n",
       " 'agoand',\n",
       " 'agoanyways',\n",
       " 'agocopyright',\n",
       " 'agohowever',\n",
       " 'agoi',\n",
       " 'agoits',\n",
       " 'agojapan',\n",
       " 'agolast',\n",
       " 'agomy',\n",
       " 'agonies',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agood',\n",
       " 'agp',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreejust',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agressive',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agua',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'aheadfor',\n",
       " 'ahem',\n",
       " 'ahern',\n",
       " 'aherns',\n",
       " 'ahhhhhhhh',\n",
       " 'ahhhhhhhhhhhhhh',\n",
       " 'ahhhhhhhhhhhhhhhhhhh',\n",
       " 'ahhhhhi',\n",
       " 'ahhhuhhh',\n",
       " 'ahold',\n",
       " 'ahora',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aida',\n",
       " 'aidan',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiel',\n",
       " 'aihands',\n",
       " 'aiken',\n",
       " 'aikenpeople',\n",
       " 'aikens',\n",
       " 'aikido',\n",
       " 'ailments',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aina',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airbed',\n",
       " 'airborne',\n",
       " 'airboxi',\n",
       " 'airconditioned',\n",
       " 'aircraft',\n",
       " 'airdrawndagger',\n",
       " 'aire',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airflow',\n",
       " 'airlift',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airplanesthe',\n",
       " 'airplay',\n",
       " 'airplus',\n",
       " 'airport',\n",
       " 'airporteven',\n",
       " 'airportexpress',\n",
       " 'airportterrible',\n",
       " 'airs',\n",
       " 'airsoft',\n",
       " 'airspace',\n",
       " 'airthis',\n",
       " 'airy',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akinshina',\n",
       " 'akira',\n",
       " 'akjee',\n",
       " 'akkad',\n",
       " 'al',\n",
       " 'aladdins',\n",
       " 'alamut',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskas',\n",
       " 'alazan',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberts',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'albumabout',\n",
       " 'albumamarantine',\n",
       " 'albumbut',\n",
       " 'albumby',\n",
       " 'albumbyalbum',\n",
       " 'albumcomment',\n",
       " 'albumdont',\n",
       " 'albumima',\n",
       " 'albuminfact',\n",
       " 'albummore',\n",
       " 'albumn',\n",
       " 'albums',\n",
       " 'albumscds',\n",
       " 'albumsever',\n",
       " 'albumsi',\n",
       " 'albumsif',\n",
       " 'albumsimple',\n",
       " 'albumsrip',\n",
       " 'albumstop',\n",
       " 'albumthemagic',\n",
       " 'albumthey',\n",
       " 'albumthis',\n",
       " 'albumway',\n",
       " 'albumwith',\n",
       " 'albumyou',\n",
       " 'albuns',\n",
       " 'albunschameleon',\n",
       " 'albuquerque',\n",
       " 'alchemy',\n",
       " 'alchol',\n",
       " 'alcohol',\n",
       " 'alcott',\n",
       " 'alcotts',\n",
       " 'alcántara',\n",
       " 'aldous',\n",
       " 'aleady',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alertative',\n",
       " 'alerted',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alexis',\n",
       " 'alfalfa',\n",
       " 'alfalfas',\n",
       " 'alfie',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'alfreds',\n",
       " 'algebra',\n",
       " 'algeria',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algun',\n",
       " 'alhajs',\n",
       " 'alhambra',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicelisawilcoxis',\n",
       " 'alices',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienating',\n",
       " 'alienfly',\n",
       " 'alienindependence',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alistair',\n",
       " 'alister',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'alivenot',\n",
       " 'alivesome',\n",
       " 'alkaline',\n",
       " 'alladded',\n",
       " 'allafter',\n",
       " 'allagory',\n",
       " 'allan',\n",
       " 'allaround',\n",
       " 'allay',\n",
       " 'allchristopher',\n",
       " 'allclad',\n",
       " 'allclay',\n",
       " 'alldate',\n",
       " 'alldeadly',\n",
       " 'alldeep',\n",
       " 'alldigital',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegorical',\n",
       " 'allegories',\n",
       " 'allegory',\n",
       " 'allegria',\n",
       " 'allen',\n",
       " 'allencompassing',\n",
       " 'allende',\n",
       " 'allens',\n",
       " 'allenwannabe',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviated',\n",
       " 'allhighly',\n",
       " 'allhowever',\n",
       " 'alli',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allience',\n",
       " 'allif',\n",
       " 'allignore',\n",
       " 'allim',\n",
       " 'allin',\n",
       " 'allinall',\n",
       " 'allit',\n",
       " 'allits',\n",
       " 'allleroy',\n",
       " 'alllet',\n",
       " 'allman',\n",
       " 'allneed',\n",
       " 'allnot',\n",
       " 'allo',\n",
       " 'allold',\n",
       " 'allone',\n",
       " 'allot',\n",
       " 'allother',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allpowerful',\n",
       " 'allready',\n",
       " 'allrent',\n",
       " 'allright',\n",
       " 'allsecond',\n",
       " 'allshe',\n",
       " 'allsinging',\n",
       " 'allso',\n",
       " 'allstar',\n",
       " 'alltell',\n",
       " 'allthe',\n",
       " 'allthis',\n",
       " 'alltime',\n",
       " 'alltoobrief',\n",
       " 'allude',\n",
       " 'alludes',\n",
       " 'alluminum',\n",
       " 'allure',\n",
       " 'allured',\n",
       " 'alluring',\n",
       " 'allusions',\n",
       " 'allwritten',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almanac',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'almostimmediate',\n",
       " 'almostmonthold',\n",
       " 'alone',\n",
       " 'alonecontains',\n",
       " 'alonei',\n",
       " 'aloneit',\n",
       " 'alonethe',\n",
       " 'alonethere',\n",
       " 'along',\n",
       " 'alongcarlos',\n",
       " 'alongside',\n",
       " 'alonme',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alous',\n",
       " 'alowed',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alrawandi',\n",
       " 'already',\n",
       " 'alreadyin',\n",
       " 'alreadyits',\n",
       " 'alreadynext',\n",
       " 'alreadysad',\n",
       " 'alreadythe',\n",
       " 'alredy',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alsoall',\n",
       " 'alsorans',\n",
       " 'alsothe',\n",
       " 'alsou',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'altec',\n",
       " 'alter',\n",
       " 'alterations',\n",
       " 'alterative',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternametal',\n",
       " 'alternate',\n",
       " 'alternated',\n",
       " 'alternatescenario',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'alternator',\n",
       " 'although',\n",
       " 'althought',\n",
       " 'althoughthe',\n",
       " 'altitude',\n",
       " 'altitudes',\n",
       " 'altius',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'altos',\n",
       " 'altruistic',\n",
       " 'aluminum',\n",
       " 'alureit',\n",
       " 'alvarez',\n",
       " 'alvin',\n",
       " 'alw',\n",
       " 'always',\n",
       " 'alwaysjust',\n",
       " 'alwayson',\n",
       " 'alya',\n",
       " 'alyson',\n",
       " 'alzheimer',\n",
       " 'alzheimers',\n",
       " 'alzhimers',\n",
       " 'ama',\n",
       " 'amadeus',\n",
       " 'amahl',\n",
       " 'amalgamation',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame(df3)\n",
    "df4.to_csv('trail113.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets get the polarity for each comment line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7967    0\n",
       "7968    1\n",
       "7969    0\n",
       "7970    0\n",
       "7971    0\n",
       "Name: Polarity, Length: 7972, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1['Polarity']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split the data set into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675     0\n",
       "402     1\n",
       "7591    0\n",
       "1917    1\n",
       "1150    1\n",
       "       ..\n",
       "4931    1\n",
       "3264    1\n",
       "1653    0\n",
       "2607    0\n",
       "2732    0\n",
       "Name: Polarity, Length: 6377, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946    0\n",
       "5356    0\n",
       "521     0\n",
       "5900    1\n",
       "6955    1\n",
       "       ..\n",
       "5739    0\n",
       "6603    1\n",
       "4761    0\n",
       "597     0\n",
       "826     0\n",
       "Name: Polarity, Length: 1595, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6377, 35983)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1595, 35983)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will start logistic regression on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "YHAT=LogisticRegression()\n",
    "YHAT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have very high number of words, we will have a look at some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a readymade syntex for printing top 25 rows for +ve and -ve polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you want to change the number of 25 to a different number, change n=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you see this out, please varify broadly -ve and +ve are correct, else interchage 'positive' and 'negative' in the below syntex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tNegative\t\t\t\t\t\tPositive\n",
      "________________________________________________________________________________________________\n",
      "\t-1.2351\tcommentary     \t\t\t\t1.4079\tmissed         \n",
      "\t-1.2097\texcept         \t\t\t\t1.1081\tshots          \n",
      "\t-1.1564\trealism        \t\t\t\t1.0895\tclarity        \n",
      "\t-1.1365\tstorage        \t\t\t\t1.0655\twash           \n",
      "\t-1.1176\tcollege        \t\t\t\t1.0158\tcollect        \n",
      "\t-1.1137\tmaps           \t\t\t\t1.0069\tmetal          \n",
      "\t-1.1119\timagination    \t\t\t\t0.9849\ttoes           \n",
      "\t-1.1114\tfish           \t\t\t\t0.9774\tclasses        \n",
      "\t-1.1015\thappening      \t\t\t\t0.9730\toffice         \n",
      "\t-1.0967\tinstructions   \t\t\t\t0.9568\tsmaller        \n",
      "\t-1.0660\treaders        \t\t\t\t0.9551\tneedless       \n",
      "\t-1.0596\tdeeper         \t\t\t\t0.9521\titll           \n",
      "\t-1.0594\tpositive       \t\t\t\t0.9480\tjoe            \n",
      "\t-1.0540\tpackage        \t\t\t\t0.9411\tfive           \n",
      "\t-1.0364\tpair           \t\t\t\t0.9295\tboard          \n",
      "\t-1.0180\tannoying       \t\t\t\t0.9264\tmachine        \n",
      "\t-1.0148\tmustsee        \t\t\t\t0.9149\thumorous       \n",
      "\t-0.9866\tvcr            \t\t\t\t0.9130\tlasted         \n",
      "\t-0.9830\tbarely         \t\t\t\t0.9118\tlearning       \n",
      "\t-0.9795\tbottle         \t\t\t\t0.9094\tchildhood      \n",
      "\t-0.9788\tmeets          \t\t\t\t0.9046\twonderfully    \n",
      "\t-0.9787\tmount          \t\t\t\t0.9023\tcheesy         \n",
      "\t-0.9778\tchill          \t\t\t\t0.8923\tsearched       \n",
      "\t-0.9737\trelated        \t\t\t\t0.8876\tkick           \n",
      "\t-0.9620\tpresentation   \t\t\t\t0.8850\tawsome         \n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, YHAT, n=25):\n",
    "    d = {}\n",
    "    a=0\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(YHAT.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    print(\"\\t\\t\\tNegative\\t\\t\\t\\t\\t\\tPositive\")\n",
    "    print(\"________________________________________________________________________________________________\")\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        d[a]=fn_1\n",
    "        a+=1\n",
    "    \n",
    "show_most_informative_features(cv,YHAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = YHAT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can optically see the accuracy of few outputs of y_pred vs y-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946    0\n",
       "5356    0\n",
       "521     0\n",
       "5900    1\n",
       "6955    1\n",
       "       ..\n",
       "5739    0\n",
       "6603    1\n",
       "4761    0\n",
       "597     0\n",
       "826     0\n",
       "Name: Polarity, Length: 1595, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run this syntex to check the accuracy of the model. Note the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       807\n",
      "           1       0.52      0.54      0.53       788\n",
      "\n",
      "    accuracy                           0.53      1595\n",
      "   macro avg       0.53      0.53      0.53      1595\n",
      "weighted avg       0.53      0.53      0.53      1595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
